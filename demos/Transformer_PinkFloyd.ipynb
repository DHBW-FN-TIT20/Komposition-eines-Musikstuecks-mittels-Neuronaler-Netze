{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training\n",
    "\n",
    "In this section you can train the transformer model with Bach. The first section is monophony and the second with polyphony encoding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train monophony encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mukkeBude.model import MukkeBudeTransformer\n",
    "from mukkeBude.mapping import MusicMapping\n",
    "import mukkeBude.utils as utils\n",
    "import music21 as m21\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Check if GPU is found\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "mapping = MusicMapping.create()\n",
    "\n",
    "# optional save the mapping\n",
    "# mapping.save(\"mapping.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the music21 corpus for the bach training data. </br>\n",
    "You can adjust the `paths` to reduce the number of training songs. </br>\n",
    "</br>\n",
    "See: https://web.mit.edu/music21/doc/about/referenceCorpus.html\n",
    "\n",
    "To use custom training data use:\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "paths = list(Path(\"./dataset/Pokemon\").rglob(\"*.midi\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paths = list(Path(\"../mukkeBude/songs/pinkfloyd/\").rglob(\"*.mid*\"))\n",
    "\n",
    "print(f\"Found {len(paths)} songs in corpus.\")\n",
    "encoded_songs = utils.load_dataset_lstm(paths, 64, mapping, raw_songs=True, corpus=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "utils.create_train_data(encoded_songs, \"raw_train_ds_mono_pinkfloyd.txt\")\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = MukkeBudeTransformer(mapping)\n",
    "print(model)\n",
    "\n",
    "logdir = \"logs/pinkfloyd_transformer\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.train(\"raw_train_ds_mono_pinkfloyd.txt\", min_training_seq_len=32, epochs=100, tensorboard_callback=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"PinkFloyd_soloMelodie_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/bach_transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train polyphony encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 12:26:56.438481: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from mukkeBude.model import MukkeBudeTransformer\n",
    "from mukkeBude.mapping import MusicMapping\n",
    "import mukkeBude.utils as utils\n",
    "import music21 as m21\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Check if GPU is found\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "mapping = MusicMapping.create()\n",
    "\n",
    "# optional save the mapping\n",
    "# mapping.save(\"mapping.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the music21 corpus for the bach training data. </br>\n",
    "You can adjust the `paths` to reduce the number of training songs. </br>\n",
    "</br>\n",
    "See: https://web.mit.edu/music21/doc/about/referenceCorpus.html\n",
    "\n",
    "To load custom training data use:\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "paths = list(Path(\"./dataset/Pokemon\").rglob(\"*.midi\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 songs in corpus.\n",
      "Songs encoded: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:341: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Note\").highestTime,\n",
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:342: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Chord\").highestTime,\n"
     ]
    }
   ],
   "source": [
    "# Load songs\n",
    "from pathlib import Path\n",
    "paths = list(Path(\"../mukkeBude/songs/pinkfloyd/\").rglob(\"*.mid*\"))\n",
    "\n",
    "print(f\"Found {len(paths)} songs in corpus.\")\n",
    "\n",
    "encoded_songs = []\n",
    "for path in paths:\n",
    "    song = utils.read_single(path)\n",
    "    # song = utils.transpose_songs([song,])[0]\n",
    "    encoded_song = utils.to_polyphonic_encoding(song, mapping)\n",
    "    encoded_songs.append(mapping.textify(encoded_song))\n",
    "\n",
    "print(f\"Songs encoded: {len(encoded_songs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "utils.create_train_data(encoded_songs, \"raw_train_ds_poly_pinkfloyd.txt\")\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, None, 256)        780288    \n",
      " g_1 (TokenAndPositionEmbedd                                     \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " transformer_decoder_4 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_5 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_6 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_7 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 1000)        257000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,616,284\n",
      "Trainable params: 2,616,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "2/2 - 4s - loss: 6.5171 - accuracy: 0.0938 - 4s/epoch - 2s/step\n",
      "Epoch 2/30\n",
      "2/2 - 0s - loss: 3.8188 - accuracy: 0.3125 - 35ms/epoch - 17ms/step\n",
      "Epoch 3/30\n",
      "2/2 - 0s - loss: 2.6211 - accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
      "Epoch 4/30\n",
      "2/2 - 0s - loss: 1.6982 - accuracy: 0.6562 - 38ms/epoch - 19ms/step\n",
      "Epoch 5/30\n",
      "2/2 - 0s - loss: 1.0662 - accuracy: 0.8125 - 35ms/epoch - 18ms/step\n",
      "Epoch 6/30\n",
      "2/2 - 0s - loss: 0.6206 - accuracy: 0.9688 - 37ms/epoch - 19ms/step\n",
      "Epoch 7/30\n",
      "2/2 - 0s - loss: 0.3847 - accuracy: 0.9375 - 36ms/epoch - 18ms/step\n",
      "Epoch 8/30\n",
      "2/2 - 0s - loss: 0.2255 - accuracy: 0.9688 - 38ms/epoch - 19ms/step\n",
      "Epoch 9/30\n",
      "2/2 - 0s - loss: 0.1614 - accuracy: 0.9375 - 37ms/epoch - 19ms/step\n",
      "Epoch 10/30\n",
      "2/2 - 0s - loss: 0.1091 - accuracy: 0.9688 - 37ms/epoch - 18ms/step\n",
      "Epoch 11/30\n",
      "2/2 - 0s - loss: 0.0958 - accuracy: 0.9688 - 36ms/epoch - 18ms/step\n",
      "Epoch 12/30\n",
      "2/2 - 0s - loss: 0.0842 - accuracy: 0.9688 - 35ms/epoch - 17ms/step\n",
      "Epoch 13/30\n",
      "2/2 - 0s - loss: 0.0690 - accuracy: 0.9688 - 36ms/epoch - 18ms/step\n",
      "Epoch 14/30\n",
      "2/2 - 0s - loss: 0.0638 - accuracy: 0.9688 - 37ms/epoch - 19ms/step\n",
      "Epoch 15/30\n",
      "2/2 - 0s - loss: 0.0674 - accuracy: 0.9688 - 37ms/epoch - 18ms/step\n",
      "Epoch 16/30\n",
      "2/2 - 0s - loss: 0.0630 - accuracy: 0.9688 - 37ms/epoch - 19ms/step\n",
      "Epoch 17/30\n",
      "2/2 - 0s - loss: 0.0592 - accuracy: 0.9688 - 36ms/epoch - 18ms/step\n",
      "Epoch 18/30\n",
      "2/2 - 0s - loss: 0.0561 - accuracy: 0.9688 - 37ms/epoch - 18ms/step\n",
      "Epoch 19/30\n",
      "2/2 - 0s - loss: 0.0609 - accuracy: 0.9375 - 36ms/epoch - 18ms/step\n",
      "Epoch 20/30\n",
      "2/2 - 0s - loss: 0.0559 - accuracy: 0.9688 - 45ms/epoch - 22ms/step\n",
      "Epoch 21/30\n",
      "2/2 - 0s - loss: 0.0553 - accuracy: 0.9688 - 34ms/epoch - 17ms/step\n",
      "Epoch 22/30\n",
      "2/2 - 0s - loss: 0.0550 - accuracy: 0.9688 - 39ms/epoch - 19ms/step\n",
      "Epoch 23/30\n",
      "2/2 - 0s - loss: 0.0535 - accuracy: 0.9688 - 35ms/epoch - 17ms/step\n",
      "Epoch 24/30\n",
      "2/2 - 0s - loss: 0.0514 - accuracy: 0.9688 - 34ms/epoch - 17ms/step\n",
      "Epoch 25/30\n",
      "2/2 - 0s - loss: 0.0497 - accuracy: 0.9688 - 36ms/epoch - 18ms/step\n",
      "Epoch 26/30\n",
      "2/2 - 0s - loss: 0.0570 - accuracy: 0.9688 - 35ms/epoch - 18ms/step\n",
      "Epoch 27/30\n",
      "2/2 - 0s - loss: 0.0569 - accuracy: 0.9688 - 36ms/epoch - 18ms/step\n",
      "Epoch 28/30\n",
      "2/2 - 0s - loss: 0.0575 - accuracy: 0.9688 - 35ms/epoch - 17ms/step\n",
      "Epoch 29/30\n",
      "2/2 - 0s - loss: 0.0493 - accuracy: 0.9688 - 35ms/epoch - 17ms/step\n",
      "Epoch 30/30\n",
      "2/2 - 0s - loss: 0.0486 - accuracy: 0.9688 - 35ms/epoch - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = MukkeBudeTransformer(mapping)\n",
    "print(model)\n",
    "\n",
    "logdir = \"logs/pinkfloyd_transformer\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.train(\"raw_train_ds_poly_pinkfloyd.txt\", min_training_seq_len=128, epochs=30, tensorboard_callback=tensorboard_callback, batch_size=1, seq_len=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/bach_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deglasfl/repos/mukkeBude/mukkeBude/model/preTrainedModels/PinkFloyd_polyphonie_transformer.h5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"PinkFloyd_polyphonie_transformer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate music\n",
    "\n",
    "In this section you can generate music with a pre trained transformer model. The first section is monophony and the second with polyphony encoding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generate monophony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mukkeBude.mapping import MusicMapping\n",
    "from mukkeBude.model import MukkeBudeTransformer\n",
    "import mukkeBude.utils as utils\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "from mukkeBude.mapping import SPECIAL_TOKS\n",
    "from mukkeBude.mapping import REST\n",
    "from mukkeBude.mapping import WAIT_LSTM\n",
    "\n",
    "# Check if GPU is found\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "mapping = MusicMapping.create()\n",
    "\n",
    "# optional save the mapping\n",
    "# mapping.save(\"mapping.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to know the trainings data and the same trainings parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MukkeBudeTransformer.load(mapping, \"PinkFloyd_soloMelodie_transformer\", \"raw_train_ds_mono_pinkfloyd.txt\", min_training_seq_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create song\n",
    "# TODO\n",
    "# generated_song = model.generate(\"n60 _ _ _ n55 _ _ _ n52 _ _ _ n48 _ n47 _ n60 _ _ _ n60\", max_length=500)\n",
    "\n",
    "# Remove REST and WAIT_LSTM from SPECIAL_TOKS\n",
    "special_tokens = SPECIAL_TOKS.copy()\n",
    "special_tokens.remove(REST)\n",
    "special_tokens.remove(WAIT_LSTM)\n",
    "\n",
    "generated_song = \" \".join(utils.replace_special_tokens(generated_song.split(), WAIT_LSTM, special_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_song = utils.decode_songs_old(generated_song)\n",
    "print(generated_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"generated_song_pinkfloyd_trans_mono.midi\")\n",
    "utils.write_midi(new_song, path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate polyphony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from mukkeBude.mapping import MusicMapping\n",
    "from mukkeBude.model import MukkeBudeTransformer\n",
    "import mukkeBude.utils as utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from mukkeBude.mapping import SPECIAL_TOKS\n",
    "from mukkeBude.mapping import SEP\n",
    "from mukkeBude.mapping import BOS\n",
    "\n",
    "# Check if GPU is found\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "mapping = MusicMapping.create()\n",
    "\n",
    "# optional save the mapping\n",
    "# mapping.save(\"mapping.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to know the trainings data and the same trainings parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MukkeBudeTransformer.load(mapping, \"PinkFloyd_polyphonie_transformer\", \"raw_train_ds_poly_pinkfloyd.txt\", min_training_seq_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n69 d4 xxsep d4 n73 d2 n69 d2 xxsep d2 n73 d3 n69 d3 xxsep d3 n69 d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 n74 d1 xxsep d1 xxsep d1 n74 d16 n74 d16 n69 d1 xxsep d1 n74 d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 n74 d1 xxsep d1 xxsep d1 n74 d16 n74 d16 n74 d16 n74 d16 n74 d16 n74 d16 n74 d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 xxsep d1 n74 d16 n74 d16 n74 d16 n74 d1 n78 d16 n74 d16 n69 d1 xxsep d1 n74 d16 n74 d1 d1 n74 d16 n74 d16 n74 d16 n74 d16 n74 d16 n74 d1 xxsep d1 xxsep d1 n74 d16 n69 d16 n69 d16 n74 d16 n74 d16 n74 d1 xxsep d1 xxsep d1 xxsep d1 n74 d1 xxsep d1 xxsep d1 xxsep d1 n78 d16 n74 d16 n69 d16 n74 d16 n74 d16 n74 d1 xxsep d1 n74 d16 n69 d16 n74 d16 n74 d16 n74 d1 xxsep d1 xxsep d1 n74 d16 n74 d16 n74 d16 n69 d16 n74 d16 n74 d16 n69 d16 n74 d16 n74 d16 n69\n"
     ]
    }
   ],
   "source": [
    "# Create song\n",
    "generated_song = model.generate(\"n69 d4 xxsep d4 n73 d2 n69 d2 xxsep d2 n73 d3 n69 d3 xxsep d3 n69 d1 xxsep d1\", max_length=200, probability=0.8)\n",
    "\n",
    "# Remove REST and WAIT_LSTM from SPECIAL_TOKS\n",
    "special_tokens = SPECIAL_TOKS.copy()\n",
    "special_tokens.remove(SEP)\n",
    "special_tokens.remove(BOS)\n",
    "\n",
    "generated_song = \" \".join(utils.replace_special_tokens(generated_song.split(), \"d4\", special_tokens))\n",
    "print(generated_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to music21\n",
    "new_song_ints = mapping.numericalize(generated_song.split(\" \"))\n",
    "new_song_ints = np.array(new_song_ints)\n",
    "\n",
    "new_song = utils.from_polyphonic_encoding(new_song_ints, mapping, bpm=100)\n",
    "\n",
    "path = Path(\"generated_song_pinkfloyd_trans_poly.midi\")\n",
    "utils.write_midi(new_song, path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
