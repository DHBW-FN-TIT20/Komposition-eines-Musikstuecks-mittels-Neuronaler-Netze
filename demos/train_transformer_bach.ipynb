{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 19:01:17.805508: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from mukkeBude.model import MukkeBudeTransformer\n",
    "from mukkeBude.mapping import MusicMapping\n",
    "import mukkeBude.utils as utils\n",
    "import music21 as m21\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if GPU is found\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "mapping = MusicMapping.create()\n",
    "mapping.save(\"mapping.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 songs in corpus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:299: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Note\").highestTime,\n",
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:300: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Chord\").highestTime,\n",
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:299: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Note\").highestTime,\n",
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:300: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Chord\").highestTime,\n",
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:299: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Note\").highestTime,\n",
      "/home/deglasfl/repos/mukkeBude/mukkeBude/utils.py:300: StreamIteratorInefficientWarning: highestTime is not defined on StreamIterators. Call .stream() first for efficiency\n",
      "  song.flat.getElementsByClass(\"Chord\").highestTime,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs encoded: 100\n"
     ]
    }
   ],
   "source": [
    "# Load songs\n",
    "paths = m21.corpus.getComposer('bach')\n",
    "# paths = paths[:100]\n",
    "print(f\"Found {len(paths)} songs in corpus.\")\n",
    "\n",
    "encoded_songs = []\n",
    "for model_path in paths:\n",
    "    song = utils.read_single_from_corpus(model_path)\n",
    "    encoded_song = utils.to_polyphonic_encoding(song, mapping)\n",
    "    encoded_songs.append(mapping.textify(encoded_song))\n",
    "\n",
    "print(f\"Songs encoded: {len(encoded_songs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "utils.create_train_data(encoded_songs, \"raw_train_ds.txt\")\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, None, 256)        780288    \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_decoder (Transf  (None, None, 256)        394749    \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      " transformer_decoder_1 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_2 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_3 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 1000)        257000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,616,284\n",
      "Trainable params: 2,616,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "2/2 - 5s - loss: 5.8297 - perplexity: 340.2556 - 5s/epoch - 3s/step\n",
      "Epoch 2/30\n",
      "2/2 - 1s - loss: 3.9303 - perplexity: 50.9231 - 1s/epoch - 690ms/step\n",
      "Epoch 3/30\n",
      "2/2 - 1s - loss: 3.1944 - perplexity: 24.3954 - 1s/epoch - 733ms/step\n",
      "Epoch 4/30\n",
      "2/2 - 2s - loss: 2.8095 - perplexity: 16.6008 - 2s/epoch - 751ms/step\n",
      "Epoch 5/30\n",
      "2/2 - 2s - loss: 2.5210 - perplexity: 12.4412 - 2s/epoch - 777ms/step\n",
      "Epoch 6/30\n",
      "2/2 - 2s - loss: 2.3264 - perplexity: 10.2407 - 2s/epoch - 761ms/step\n",
      "Epoch 7/30\n",
      "2/2 - 1s - loss: 2.2008 - perplexity: 9.0321 - 1s/epoch - 698ms/step\n",
      "Epoch 8/30\n",
      "2/2 - 1s - loss: 2.1456 - perplexity: 8.5475 - 1s/epoch - 710ms/step\n",
      "Epoch 9/30\n",
      "2/2 - 1s - loss: 2.0962 - perplexity: 8.1350 - 1s/epoch - 694ms/step\n",
      "Epoch 10/30\n",
      "2/2 - 1s - loss: 2.0584 - perplexity: 7.8332 - 1s/epoch - 690ms/step\n",
      "Epoch 11/30\n",
      "2/2 - 1s - loss: 2.0390 - perplexity: 7.6826 - 1s/epoch - 708ms/step\n",
      "Epoch 12/30\n",
      "2/2 - 1s - loss: 2.0296 - perplexity: 7.6111 - 1s/epoch - 701ms/step\n",
      "Epoch 13/30\n",
      "2/2 - 1s - loss: 2.0103 - perplexity: 7.4659 - 1s/epoch - 734ms/step\n",
      "Epoch 14/30\n",
      "2/2 - 1s - loss: 1.9922 - perplexity: 7.3318 - 1s/epoch - 715ms/step\n",
      "Epoch 15/30\n",
      "2/2 - 1s - loss: 1.9789 - perplexity: 7.2346 - 1s/epoch - 687ms/step\n",
      "Epoch 16/30\n",
      "2/2 - 1s - loss: 1.9680 - perplexity: 7.1561 - 1s/epoch - 695ms/step\n",
      "Epoch 17/30\n",
      "2/2 - 1s - loss: 1.9547 - perplexity: 7.0618 - 1s/epoch - 702ms/step\n",
      "Epoch 18/30\n",
      "2/2 - 1s - loss: 1.9360 - perplexity: 6.9309 - 1s/epoch - 697ms/step\n",
      "Epoch 19/30\n",
      "2/2 - 1s - loss: 1.9262 - perplexity: 6.8636 - 1s/epoch - 702ms/step\n",
      "Epoch 20/30\n",
      "2/2 - 1s - loss: 1.9157 - perplexity: 6.7914 - 1s/epoch - 711ms/step\n",
      "Epoch 21/30\n",
      "2/2 - 1s - loss: 1.9032 - perplexity: 6.7073 - 1s/epoch - 703ms/step\n",
      "Epoch 22/30\n",
      "2/2 - 1s - loss: 1.8987 - perplexity: 6.6770 - 1s/epoch - 709ms/step\n",
      "Epoch 23/30\n",
      "2/2 - 1s - loss: 1.8872 - perplexity: 6.6008 - 1s/epoch - 705ms/step\n",
      "Epoch 24/30\n",
      "2/2 - 1s - loss: 1.8681 - perplexity: 6.4758 - 1s/epoch - 731ms/step\n",
      "Epoch 25/30\n",
      "2/2 - 1s - loss: 1.8516 - perplexity: 6.3697 - 1s/epoch - 723ms/step\n",
      "Epoch 26/30\n",
      "2/2 - 1s - loss: 1.8397 - perplexity: 6.2945 - 1s/epoch - 686ms/step\n",
      "Epoch 27/30\n",
      "2/2 - 1s - loss: 1.8209 - perplexity: 6.1773 - 1s/epoch - 712ms/step\n",
      "Epoch 28/30\n",
      "2/2 - 1s - loss: 1.7919 - perplexity: 6.0007 - 1s/epoch - 700ms/step\n",
      "Epoch 29/30\n",
      "2/2 - 1s - loss: 1.7654 - perplexity: 5.8440 - 1s/epoch - 695ms/step\n",
      "Epoch 30/30\n",
      "2/2 - 1s - loss: 1.7413 - perplexity: 5.7049 - 1s/epoch - 686ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f483161f100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model = MukkeBudeTransformer(mapping)\n",
    "print(model)\n",
    "\n",
    "logdir = \"logs/bach_transformer\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.train(\"raw_train_ds.txt\", min_training_seq_len=32, epochs=30, tensorboard_callback=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8496df56bd7d1a7c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8496df56bd7d1a7c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/bach_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deglasfl/repos/mukkeBude/mukkeBude/model/preTrainedModels/Bach_soloMelodie_transformer.h5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"Bach_soloMelodie_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create song\n",
    "generated_song = model.generate(\"xxbos n67 d4 n62 d4 n58 d4 n43 d4 xxsep d4 n67 d4 n62 d4 n58 d4 n55 d4 xxsep d4 n69 d4 n62 d4 n57 d4 n54 d4 xxsep\", max_length=2048, probability=0.8)\n",
    "new_song_str = generated_song.numpy().decode(\"utf-8\")\n",
    "print(f\"CLEAN SONG: {new_song_str}\\n\\n\")\n",
    "\n",
    "print(new_song_str[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to music21\n",
    "new_song_ints = mapping.numericalize(new_song_str.split(\" \"))\n",
    "new_song_ints = np.array(new_song_ints)\n",
    "\n",
    "print(new_song_ints[:50])\n",
    "print(mapping.textify(new_song_ints[:50]))\n",
    "\n",
    "new_song = utils.from_polyphonic_encoding(new_song_ints, mapping, bpm=100)\n",
    "model_path = Path(\"generated_song_bach.mid\")\n",
    "utils.write_midi(new_song, model_path)\n",
    "utils.write_musicxml(new_song, \"generated_song_bach.musicxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open song in MuseScore (Linux if installed)\n",
    "!musescore4portable {path.absolute()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9052d763eeeacaf5da08a840d251d734fa4deea148f97d28b11062c8c516292f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
