{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f2f708-07f9-410f-a191-a397afb64d44",
   "metadata": {},
   "source": [
    "# Erstellen und Trainieren der KI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d00b07f-6885-459d-9ebb-518af238de45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Needed imports\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "\n",
    "# Needed variabel\n",
    "dataset_folder = Path(__file__).parent / \"dataset\"\n",
    "sequence_length = 64\n",
    "model_path = Path(__file__).parent / \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945c9b46-cd83-4c9b-8b8e-18fdfdebbc80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576,)\n",
      "[ 5 16  9 16 16 16 10 16 11 16]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "songs = np.load(dataset_folder / \"songs.npy\")\n",
    "\n",
    "print(songs.shape)\n",
    "print(songs[:10])\n",
    "\n",
    "songs = songs.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca9947-4788-4cf2-bdb1-b5880d03cbfd",
   "metadata": {},
   "source": [
    "## Erstellen der Trainingsdaten\n",
    "Wir erstellen sequenzen von eienr bestimmten länge und sagen dem Netzwerk, ok was kommt als nächstes. Dies macht man so lange, bis man alle Daten durchhat. Das schafft man, indem man die die Trainignsdaten nimmt, ein Teil herausschneided und dan den Ausschnit zum Herusschneiden immer eins weiter nach rechts shifted, bis man alle Daten durch ist.\n",
    "\n",
    "```bash\n",
    "# Data\n",
    "[12, 13, 14, 15, 16, 17, ...]\n",
    "\n",
    "# Erster input und targed\n",
    "[12, 13] -> 14\n",
    "\n",
    "#Zweiter input und targed\n",
    "[13, 14] -> 15\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "794dae6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 100 symbols, 64 sl\n",
    "# 100 - 64 = 36\n",
    "num_sequences = len(songs) - sequence_length\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(num_sequences):\n",
    "    inputs.append(songs[i:i+sequence_length])\n",
    "    targets.append(songs[i+sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7801c99a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sequences: 2512\n",
      "the first input sequence:\n",
      "[5, 16, 9, 16, 16, 16, 10, 16, 11, 16, 16, 10, 9, 16, 13, 16, 16, 16, 16, 16, 10, 16, 16, 16, 12, 16, 11, 16, 16, 10, 9, 16, 8, 16, 16, 16, 9, 16, 10, 16, 16, 16, 16, 16, 17, 16, 16, 16, 5, 16, 13, 16, 16, 16, 13, 16, 11, 16, 16, 10, 9, 16, 15, 16]\n",
      "the first target sequence:\n",
      "16\n",
      "\n",
      "The whole dataset for the first input sequence:\n",
      "[5, 16, 9, 16, 16, 16, 10, 16, 11, 16, 16, 10, 9, 16, 13, 16, 16, 16, 16, 16, 10, 16, 16, 16, 12, 16, 11, 16, 16, 10, 9, 16, 8, 16, 16, 16, 9, 16, 10, 16, 16, 16, 16, 16, 17, 16, 16, 16, 5, 16, 13, 16, 16, 16, 13, 16, 11, 16, 16, 10, 9, 16, 15, 16, 16]\n",
      "\n",
      "2512 2512\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num sequences: {len(inputs)}\")\n",
    "print(\"the first input sequence:\")\n",
    "print(inputs[0])\n",
    "print(\"the first target sequence:\")\n",
    "print(targets[0])\n",
    "print()\n",
    "print(\"The whole dataset for the first input sequence:\")\n",
    "print(songs[:sequence_length+1])\n",
    "print()\n",
    "print(len(inputs), len(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c1777",
   "metadata": {},
   "source": [
    "## One-Hot encoding\n",
    "Jeder mögliche Wert den es geben kann wird als Reihe in einer tabelle gesehen.\n",
    "![](./Bilder/oenHot.png)\n",
    "\n",
    "In unserem Fall ist ist die größe der Tabelle gleich der Anzahl an Elemente in unserem `mapping.json`. In unserem Fall sollte das 18 sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b011083d-19d2-49be-9bcf-6f20716143ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1814cb2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vacabulay_size = len(np.unique(songs))\n",
    "inputs = keras.utils.to_categorical(inputs, num_classes=vacabulay_size)\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f2c7853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 18\n",
      "(2512, 64, 18)\n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {vacabulay_size}\")\n",
    "print(inputs.shape)\n",
    "print()\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "770e4b7f-49d7-49e2-b2cc-5694b4369156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2512,)\n",
      "\n",
      "[16 16 16 ...  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28153ec1",
   "metadata": {},
   "source": [
    "## Erstellen des Modells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ec501d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_layer_size = vacabulay_size  # Number of unique symbols in the dataset\n",
    "hidden_layer_sizes = [256, 256]      # Number of neurons in each hidden layer\n",
    "loss = \"sparse_categorical_crossentropy\"    # Loss function\n",
    "optimizer = \"adam\"                          # Optimizer\n",
    "activation = \"softmax\"                      # Activation function\n",
    "learning_rate = 0.001                       # Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36be69",
   "metadata": {},
   "source": [
    "Hier erstellt man nun das konkrete Netzwerk.\n",
    "\n",
    "`shape = (None, output_layer_size)`\n",
    "1. Variable `None`-> Wie viele Zeitstemnpel hat man. Bei None wird das automatisch ermittelt \n",
    "2. Variable `output_layer_size` -> Wie viele Inputs hat man pro Eingabe. Dies ist hier die Anzahl der verwendeten Noten\n",
    "\n",
    "Dem layer wird dann hidden LSTM layer hinzugefügt und ein Dropout, welches gegen Overfitting hilft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "728c9cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the model achitecture\n",
    "# model = keras.Sequential() # <- Would be a good idea to use this\n",
    "\n",
    "# Input layer\n",
    "input_layer = keras.layers.Input(shape=(None, output_layer_size))\n",
    "\n",
    "# Hidden layers\n",
    "x = input_layer\n",
    "for hidden_layer_size in hidden_layer_sizes:\n",
    "    x = keras.layers.LSTM(hidden_layer_size, return_sequences=True)(x)\n",
    "\n",
    "# Avoid overfitting\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "# Output layer. Full connection -> Dense\n",
    "output_layer = keras.layers.Dense(output_layer_size, activation=activation)(x)\n",
    "\n",
    "# The actual model\n",
    "model = keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ead2634c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e05c900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 18)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 256)         281600    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 256)         525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 18)          4626      \n",
      "=================================================================\n",
      "Total params: 811,538\n",
      "Trainable params: 811,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290e7dd",
   "metadata": {},
   "source": [
    "## Trainiere das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "811c61c1-8bf6-48c6-88af-5c9d72a2f145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2512, 64, 18)\n",
      "(2512,)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33617394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [32 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [32 64]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at C:\\Users\\Florian Glaser\\AppData\\Local\\Temp\\ipykernel_20936\\1927455679.py:4) ]] [Op:__inference_train_function_5586]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m  \u001b[38;5;66;03m# TODO Equal to sequence_length ?\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Dokumente2\\Python_Programme\\Komposition-eines-Musikstuecks-mittels-Neuronaler-Netze\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Dokumente2\\Python_Programme\\Komposition-eines-Musikstuecks-mittels-Neuronaler-Netze\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Dokumente2\\Python_Programme\\Komposition-eines-Musikstuecks-mittels-Neuronaler-Netze\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mD:\\Dokumente2\\Python_Programme\\Komposition-eines-Musikstuecks-mittels-Neuronaler-Netze\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Dokumente2\\Python_Programme\\Komposition-eines-Musikstuecks-mittels-Neuronaler-Netze\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\Dokumente2\\Python_Programme\\Komposition-eines-Musikstuecks-mittels-Neuronaler-Netze\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\Dokumente2\\Python_Programme\\Komposition-eines-Musikstuecks-mittels-Neuronaler-Netze\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [32 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [32 64]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at C:\\Users\\Florian Glaser\\AppData\\Local\\Temp\\ipykernel_20936\\1927455679.py:4) ]] [Op:__inference_train_function_5586]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 64  # TODO Equal to sequence_length ?\n",
    "\n",
    "model.fit(inputs, targets, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22686e",
   "metadata": {},
   "source": [
    "## Speicher das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac5fcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
