{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('trained_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschränkung liegt hier bei einem Lied mit 8 Takten. Kann auch erweitert werden. Allerdings benötigt man dann ein neu traniertes Model. Das ist der Nachteil bei diesem Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_melody = '''\n",
    "A4   --   A4   --   |G#4  --   --   --   |E4  --   --   --   |F4   --   --   --   |\n",
    "D4   --   --   --   |--   --   --   --   |D4   --   --   --   |--   --   --   --   |\n",
    "E4   --   --   --   |F#4  --   --   --   |G#4  --   --   --   |A4   --   B4   --   |\n",
    "C5   --   --   --   |C4   --   --   --   |E4   --   --   --   |--   --   --   --   |\n",
    "A4   --   --   --   |G#4  --   --   --   |A4   --   --   --   |F4   --   --   --   |\n",
    "D4   --   --   --   |--   --   --   --   |D4   --   --   --   |--   --   --   --   |\n",
    "E4   --   --   --   |F#4  --   --   --   |G#4  --   --   --   |A4   --   B4   --   |\n",
    "C5   --   --   --   |C4   --   --   --   |E4   --   --   --   |A4   --   --   --   |\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_melody = given_melody.replace('\\n', '').replace('|', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "tokens = given_melody.split()\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOPRANO_MIN = 57\n",
    "SOPRANO_MAX = 81\n",
    "\n",
    "ALTO_MIN = 52\n",
    "ALTO_MAX = 74\n",
    "\n",
    "TENOR_MIN = 48\n",
    "TENOR_MAX = 69\n",
    "\n",
    "BASS_MIN = 36\n",
    "BASS_MAX = 64\n",
    "\n",
    "ranges = {\n",
    "    'soprano': {midinumber: (midinumber - SOPRANO_MIN + 1) for midinumber in range(SOPRANO_MIN, SOPRANO_MAX + 1)},\n",
    "    'alto': {midinumber: (midinumber - ALTO_MIN + 1) for midinumber in range(ALTO_MIN, ALTO_MAX + 1)},\n",
    "    'tenor': {midinumber: (midinumber - TENOR_MIN + 1) for midinumber in range(TENOR_MIN, TENOR_MAX + 1)},\n",
    "    'bass': {midinumber: (midinumber - BASS_MIN + 1) for midinumber in range(BASS_MIN, BASS_MAX + 1)},\n",
    "}\n",
    "\n",
    "reverse_ranges = {\n",
    "    'soprano': {(midinumber - SOPRANO_MIN + 1): midinumber for midinumber in range(SOPRANO_MIN, SOPRANO_MAX + 1)},\n",
    "    'alto': {(midinumber - ALTO_MIN + 1): midinumber for midinumber in range(ALTO_MIN, ALTO_MAX + 1)},\n",
    "    'tenor': {(midinumber - TENOR_MIN + 1): midinumber for midinumber in range(TENOR_MIN, TENOR_MAX + 1)},\n",
    "    'bass': {(midinumber - BASS_MIN + 1): midinumber for midinumber in range(BASS_MIN, BASS_MAX + 1)},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_note(n, rang):\n",
    "    if n == '--' or n == 'Rest':\n",
    "        ret = 0\n",
    "    else:\n",
    "        note = music21.note.Note(n)\n",
    "        ret = ranges[rang][note.pitch.midi]\n",
    "    return ret\n",
    "\n",
    "def one_hot_encode(idx, rang):\n",
    "    length = len(ranges[rang].values())\n",
    "    ret = [0] * (length + 1)\n",
    "    ret[idx] = 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [encode_note(n, 'soprano') for n in tokens] \n",
    "x = np.array([[one_hot_encode(idx, 'soprano') for idx in s]])\n",
    " # zu einem 1d array machen\n",
    "x = x.reshape(1, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The melody has been encoded, so we can pass it to the model and collect the predictions from the MiniBach model.\n",
    "\n",
    "Jetzt unterteilt man die Predictions in die verschieden Stimmen mit folgender Rechnung. Wir wissen, dass wir eine Tonrange bei Alto von 23+1 haben. Wir wissen auch unsere Chunckgröße von 128. Also:\n",
    "\n",
    "128*24=3072\n",
    "\n",
    "182*23=2944\n",
    "3072+2944=6016\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "9856\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x)\n",
    "\n",
    "predictions = predictions.reshape(-1)\n",
    "\n",
    "print(len(predictions))\n",
    "\n",
    "soprano = x.reshape(128, -1)\n",
    "alto = predictions[:3072].reshape(128, -1)\n",
    "tenor = predictions[3072:6016].reshape(128, -1)\n",
    "bass = predictions[6016:9856].reshape(128, -1)\n",
    "\n",
    "\n",
    "music = {\n",
    "    'soprano': soprano,\n",
    "    'alto': alto,\n",
    "    'tenor': tenor,\n",
    "    'bass': bass\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_note(n, rang):\n",
    "    if n == 0:\n",
    "        ret = '--'\n",
    "    else:\n",
    "        note = music21.note.Note(type='16th')        \n",
    "        note.pitch.midi = reverse_ranges[rang][n]        \n",
    "        ret = note\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = {\n",
    "    'soprano': [],\n",
    "    'alto': [],\n",
    "    'tenor': [],\n",
    "    'bass': []\n",
    "}\n",
    "\n",
    "for sixteenth in range(128):\n",
    "    for part, notes in music.items():\n",
    "        this_note = decode_note(np.argmax(notes[sixteenth]), part)\n",
    "        if this_note == '--':\n",
    "            last_note = generation[part][-1]\n",
    "            this_note = music21.note.Note(last_note.pitch.nameWithOctave, type='16th')\n",
    "            if last_note.tie:\n",
    "                this_note.tie = music21.tie.Tie('continue')\n",
    "            else:\n",
    "                last_note.tie = music21.tie.Tie('start')\n",
    "                generation[part][-1] = last_note\n",
    "                this_note.tie = music21.tie.Tie('continue')\n",
    "        else:\n",
    "            if sixteenth > 0:\n",
    "                last_note = generation[part][-1]\n",
    "                if last_note.tie:\n",
    "                    last_note.tie = music21.tie.Tie('stop')\n",
    "        generation[part].append(this_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = music21.stream.Stream()\n",
    "s.append(df.soprano.to_list())\n",
    "a = music21.stream.Stream()\n",
    "a.append(df.alto.to_list())\n",
    "print(df.alto.to_list())\n",
    "t = music21.stream.Stream()\n",
    "t.append(df.tenor.to_list())\n",
    "b = music21.stream.Stream()\n",
    "b.append(df.bass.to_list())\n",
    "stream = music21.stream.Stream([s,a,t,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generated_choral.mid'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.write('musicxml', 'generated_choral.musicxml')\n",
    "stream.write('midi', 'generated_choral.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
