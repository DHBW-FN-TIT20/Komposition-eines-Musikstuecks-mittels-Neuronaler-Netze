{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f2f708-07f9-410f-a191-a397afb64d44",
   "metadata": {},
   "source": [
    "# Erstellen und Trainieren der KI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d00b07f-6885-459d-9ebb-518af238de45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 08:26:42.637305: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 08:26:42.637326: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Needed imports\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "# Needed variabel\n",
    "dataset_folder = Path(__file__).parent / \"dataset\"\n",
    "sequence_length = 64\n",
    "model_path = Path(__file__).parent / \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945c9b46-cd83-4c9b-8b8e-18fdfdebbc80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576,)\n",
      "[13 16 16 16 16 16 12 16 11 16]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "songs = np.load(dataset_folder / \"songs.npy\")\n",
    "\n",
    "print(songs.shape)\n",
    "print(songs[:10])\n",
    "\n",
    "songs = songs.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca9947-4788-4cf2-bdb1-b5880d03cbfd",
   "metadata": {},
   "source": [
    "## Erstellen der Trainingsdaten\n",
    "Wir erstellen sequenzen von eienr bestimmten länge und sagen dem Netzwerk, ok was kommt als nächstes. Dies macht man so lange, bis man alle Daten durchhat. Das schafft man, indem man die die Trainignsdaten nimmt, ein Teil herausschneided und dan den Ausschnit zum Herusschneiden immer eins weiter nach rechts shifted, bis man alle Daten durch ist.\n",
    "\n",
    "```bash\n",
    "# Data\n",
    "[12, 13, 14, 15, 16, 17, ...]\n",
    "\n",
    "# Erster input und targed\n",
    "[12, 13] -> 14\n",
    "\n",
    "#Zweiter input und targed\n",
    "[13, 14] -> 15\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794dae6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 100 symbols, 64 sl\n",
    "# 100 - 64 = 36\n",
    "num_sequences = len(songs) - sequence_length\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(num_sequences):\n",
    "    inputs.append(songs[i:i+sequence_length])\n",
    "    targets.append(songs[i+sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7801c99a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sequences: 2512\n",
      "the first input sequence:\n",
      "[13, 16, 16, 16, 16, 16, 12, 16, 11, 16, 5, 16, 9, 16, 16, 16, 7, 16, 6, 16, 4, 16, 16, 16, 9, 16, 16, 16, 7, 16, 6, 16, 4, 16, 16, 16, 9, 16, 16, 16, 7, 16, 5, 16, 3, 16, 16, 17, 13, 16, 16, 16, 16, 16, 12, 16, 11, 16, 5, 16, 9, 16, 16, 16]\n",
      "the first target sequence:\n",
      "7\n",
      "\n",
      "The whole dataset for the first input sequence:\n",
      "[13, 16, 16, 16, 16, 16, 12, 16, 11, 16, 5, 16, 9, 16, 16, 16, 7, 16, 6, 16, 4, 16, 16, 16, 9, 16, 16, 16, 7, 16, 6, 16, 4, 16, 16, 16, 9, 16, 16, 16, 7, 16, 5, 16, 3, 16, 16, 17, 13, 16, 16, 16, 16, 16, 12, 16, 11, 16, 5, 16, 9, 16, 16, 16, 7]\n",
      "\n",
      "2512 2512\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num sequences: {len(inputs)}\")\n",
    "print(\"the first input sequence:\")\n",
    "print(inputs[0])\n",
    "print(\"the first target sequence:\")\n",
    "print(targets[0])\n",
    "print()\n",
    "print(\"The whole dataset for the first input sequence:\")\n",
    "print(songs[:sequence_length+1])\n",
    "print()\n",
    "print(len(inputs), len(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c1777",
   "metadata": {},
   "source": [
    "## One-Hot encoding\n",
    "Jeder mögliche Wert den es geben kann wird als Reihe in einer tabelle gesehen.\n",
    "![](./Bilder/oenHot.png)\n",
    "\n",
    "In unserem Fall ist ist die größe der Tabelle gleich der Anzahl an Elemente in unserem `mapping.json`. In unserem Fall sollte das 18 sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b011083d-19d2-49be-9bcf-6f20716143ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1814cb2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vacabulay_size = len(np.unique(songs))\n",
    "inputs = keras.utils.to_categorical(inputs, num_classes=vacabulay_size)\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2c7853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 18\n",
      "(2512, 64, 18)\n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 1. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {vacabulay_size}\")\n",
    "print(inputs.shape)\n",
    "print()\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "770e4b7f-49d7-49e2-b2cc-5694b4369156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2512,)\n",
      "\n",
      "[ 7 16  6 ...  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28153ec1",
   "metadata": {},
   "source": [
    "## Erstellen des Modells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ec501d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_layer_size = vacabulay_size  # Number of unique symbols in the dataset\n",
    "hidden_layer_sizes = [256]      # Number of neurons in each hidden layer\n",
    "loss = \"sparse_categorical_crossentropy\"    # Loss function\n",
    "activation = \"softmax\"                      # Activation function\n",
    "learning_rate = 0.001                       # Learning rate\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)  # Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36be69",
   "metadata": {},
   "source": [
    "Hier erstellt man nun das konkrete Netzwerk.\n",
    "\n",
    "`shape = (None, output_layer_size)`\n",
    "1. Variable `None`-> Wie viele Zeitstemnpel hat man. Bei None wird das automatisch ermittelt \n",
    "2. Variable `output_layer_size` -> Wie viele Inputs hat man pro Eingabe. Dies ist hier die Anzahl der verwendeten Noten\n",
    "\n",
    "Dem layer wird dann hidden LSTM layer hinzugefügt und ein Dropout, welches gegen Overfitting hilft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "728c9cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 08:26:43.956150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-06 08:26:43.956178: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-06 08:26:43.956198: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5193325dcd0b): /proc/driver/nvidia/version does not exist\n",
      "2023-02-06 08:26:43.956459: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# create the model achitecture\n",
    "# model = keras.Sequential() # <- Would be a good idea to use this\n",
    "\n",
    "# Input layer\n",
    "input_layer = keras.layers.Input(shape=(None, output_layer_size))\n",
    "\n",
    "# Hidden layers\n",
    "x = input_layer\n",
    "for hidden_layer_size in hidden_layer_sizes:\n",
    "    x = keras.layers.LSTM(hidden_layer_size)(x)\n",
    "\n",
    "# Avoid overfitting\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "# Output layer. Full connection -> Dense\n",
    "output_layer = keras.layers.Dense(output_layer_size, activation=activation)(x)\n",
    "\n",
    "# The actual model\n",
    "model = keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead2634c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e05c900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 18)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               281600    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 18)                4626      \n",
      "=================================================================\n",
      "Total params: 286,226\n",
      "Trainable params: 286,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "815ffc5b-bd85-43a1-b0ff-a23a7ad0b67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, 'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290e7dd",
   "metadata": {},
   "source": [
    "## Trainiere das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "811c61c1-8bf6-48c6-88af-5c9d72a2f145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2512, 64, 18)\n",
      "(2512,)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(targets.shape)\n",
    "\n",
    "shape = inputs[0].shape\n",
    "for i, x in enumerate(inputs):\n",
    "    if x.shape != shape:\n",
    "        print(f\"Error: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33617394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 08:26:44.274905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 5s 42ms/step - loss: 1.3686 - accuracy: 0.7134\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 1.1215 - accuracy: 0.7512\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 1.0539 - accuracy: 0.7600\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 1.0269 - accuracy: 0.7627\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.9697 - accuracy: 0.7643\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.9522 - accuracy: 0.7667\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.8488 - accuracy: 0.7643\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.7920 - accuracy: 0.7667\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.7660 - accuracy: 0.7707\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.7129 - accuracy: 0.7803\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.7021 - accuracy: 0.7822\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.6526 - accuracy: 0.7906\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.6251 - accuracy: 0.7934\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.5856 - accuracy: 0.8101\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.5470 - accuracy: 0.8161\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 5s 64ms/step - loss: 0.5196 - accuracy: 0.8217\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 5s 59ms/step - loss: 0.4553 - accuracy: 0.8567\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 4s 55ms/step - loss: 0.4294 - accuracy: 0.8543\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.3870 - accuracy: 0.8762\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.3994 - accuracy: 0.8933\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.3113 - accuracy: 0.9001\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.2749 - accuracy: 0.9144\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.2151 - accuracy: 0.9411\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1952 - accuracy: 0.9419\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1847 - accuracy: 0.9471\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1980 - accuracy: 0.9427\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1477 - accuracy: 0.9542\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1303 - accuracy: 0.9642\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1142 - accuracy: 0.9662\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0923 - accuracy: 0.9725\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0905 - accuracy: 0.9721\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.0700 - accuracy: 0.9825\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.0635 - accuracy: 0.9813\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.0667 - accuracy: 0.9809\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.0574 - accuracy: 0.9857\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.4632 - accuracy: 0.8738\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.3650 - accuracy: 0.8893\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1591 - accuracy: 0.9534\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.6785 - accuracy: 0.8304\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.2623 - accuracy: 0.9248\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1309 - accuracy: 0.9670\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0904 - accuracy: 0.9793\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0690 - accuracy: 0.9837\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0550 - accuracy: 0.9877\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0468 - accuracy: 0.9885\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.0442 - accuracy: 0.9885\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0360 - accuracy: 0.9928\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0350 - accuracy: 0.9924\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.0251 - accuracy: 0.9960\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0249 - accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 64  # Equal to sequence_length\n",
    "\n",
    "result = model.fit(inputs, targets, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22686e",
   "metadata": {},
   "source": [
    "## Speicher das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bac5fcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "komposition-eines-musikstuecks-mittels-neu-zath_kMP-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fb9a4554ddec3f0799123ac4cc7a41db9f945942458fc16a1fb805237e5a9a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
